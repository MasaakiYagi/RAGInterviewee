<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Assistant</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
</head>
<body>
    <div class="container">
        <h1>面談シミュレータ</h1>
        <h3>Powered by OpenAI</h3>
        <div class="image-container">
            <img src="{{ url_for('static', filename='images/character.png') }}" alt="Character Image" class="character-image">
        </div>

        <div class="log-container">
            <p>会話ログ</p>
        </div>
        <div class="scrollable-container" id="conversation"></div>
        <div id="status-container">
            <p>Status: <span id="status">{{ status }}</span></p>
        </div>
        <div class="button-container">
            <button id="start-button" class="control-button">発言開始</button>
            <button id="stop-button" class="control-button" disabled>発言終了</button>
        </div>

        <audio id="response-audio" controls style="display:none;"></audio>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        $('#start-button').on('click', function() {
            startRecording();
        });

        $('#stop-button').on('click', function() {
            stopRecording();
        });

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                    mediaRecorder.start();

                    $('#status').text('ユーザー音声聞き取り中');
                    isRecording = true;
                    updateButtonStates();

                    mediaRecorder.ondataavailable = event => {
                        audioChunks.push(event.data);
                    };
                }).catch(err => {
                    console.error('Error accessing audio stream: ', err);
                });
        }

        function stopRecording() {
            mediaRecorder.stop();
            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                convertWebMToWAV(audioBlob).then(wavBlob => {
                    sendRecording(wavBlob);
                });
                audioChunks = [];
            };

            $('#status').text('AI応答中');
            isRecording = false;
            updateButtonStates();
        }

        function convertWebMToWAV(webmBlob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.readAsArrayBuffer(webmBlob);
                reader.onloadend = () => {
                    const audioContext = new AudioContext();
                    audioContext.decodeAudioData(reader.result, buffer => {
                        const wavBuffer = audioContext.createBufferSource();
                        wavBuffer.buffer = buffer;

                        const offlineContext = new OfflineAudioContext(1, buffer.length, buffer.sampleRate);
                        const wavSource = offlineContext.createBufferSource();
                        wavSource.buffer = buffer;

                        wavSource.connect(offlineContext.destination);
                        wavSource.start();

                        offlineContext.startRendering().then(renderedBuffer => {
                            const wavData = audioBufferToWav(renderedBuffer);
                            const wavBlob = new Blob([wavData], { type: 'audio/wav' });
                            resolve(wavBlob);
                        }).catch(err => {
                            console.error('Rendering failed: ', err);
                            reject(err);
                        });
                    }, err => {
                        console.error('Decoding failed: ', err);
                        reject(err);
                    });
                };
            });
        }

        function audioBufferToWav(buffer) {
            let numOfChan = buffer.numberOfChannels,
                length = buffer.length * numOfChan * 2 + 44,
                bufferArray = new ArrayBuffer(length),
                view = new DataView(bufferArray),
                channels = [],
                i, sample,
                offset = 0,
                pos = 0;

            // write WAVE header
            setUint32(0x46464952);                         // "RIFF"
            setUint32(length - 8);                         // file length - 8
            setUint32(0x45564157);                         // "WAVE"

            setUint32(0x20746d66);                         // "fmt " chunk
            setUint32(16);                                 // length = 16
            setUint16(1);                                  // PCM (uncompressed)
            setUint16(numOfChan);
            setUint32(buffer.sampleRate);
            setUint32(buffer.sampleRate * 2 * numOfChan);  // avg. bytes/sec
            setUint16(numOfChan * 2);                      // block-align
            setUint16(16);                                 // 16-bit (hardcoded in this demo)

            setUint32(0x61746164);                         // "data" - chunk
            setUint32(length - pos - 4);                   // chunk length

            // write interleaved data
            for (i = 0; i < buffer.numberOfChannels; i++)
                channels.push(buffer.getChannelData(i));

            while (pos < length) {
                for (i = 0; i < numOfChan; i++) {             // interleave channels
                    sample = Math.max(-1, Math.min(1, channels[i][offset])); // clamp
                    sample = (sample < 0 ? sample * 0x8000 : sample * 0x7FFF) | 0; // scale to 16-bit signed int
                    view.setInt16(pos, sample, true);          // write 16-bit sample
                    pos += 2;
                }
                offset++                                     // next source sample
            }

            function setUint16(data) {
                view.setUint16(pos, data, true);
                pos += 2;
            }

            function setUint32(data) {
                view.setUint32(pos, data, true);
                pos += 4;
            }

            return bufferArray;
        }

        /*録音した音声をバックエンドに送信*/
        function sendRecording(blob) {
            const formData = new FormData();
            formData.append('audio', blob, 'recording.wav');

            $.ajax({
                url: '/transcribe',
                type: 'POST',
                data: formData,
                processData: false,
                contentType: false,
                success: function(response) {
                    handleSendRecording(response);
                }
            });
        }

        function handleSendRecording(response) {
            $('#conversation').prepend(`<p>あなた: ${response.usertext}</p>`);
            sendUserTextStreaming(response.usertext);
        }

        /*書き起こされたUserTextをバックエンドに送信*/
        function sendUserText(usertext) {
            $.ajax({
                url: '/llm',
                type: 'POST',
                contentType: 'application/json',
                data: JSON.stringify({ message: usertext }),
                success: function(response) {
                    handleUserSendText(response);
                }
            });
        }

        function handleUserSendText(response) {
            $('#conversation').prepend(`<p>インタビュイー: ${response.assistanttext}</p>`);
            sendAssistantText(response.assistanttext);
        }

        /*返されたAssistantTextをバックエンドに送信*/
        function sendAssistantText(assistanttext) {
            $.ajax({
                url: '/tts',
                type: 'POST',
                contentType: 'application/json',
                data: JSON.stringify({ message: assistanttext }),
                success: function(response) {
                    handleAssitantSendText(response);
                }
            });
        }

        function handleAssitantSendText(response) {
            const audioBase64 = response.audio;
            const audioBlob = base64ToBlob(audioBase64, 'audio/wav');
            const audioUrl = URL.createObjectURL(audioBlob);
            const audioElement = document.getElementById('response-audio');
            audioElement.src = audioUrl;
            audioElement.style.display = 'block';
            audioElement.play();

            $('#status').text('停止中');
            updateButtonStates();
        }

        /*応答生成と音声生成を同時にストリーミング*/
        function sendUserTextStreaming(usertext) {
            const conversationElement = $('#conversation');
            const audioElement = document.getElementById('response-audio');
            const responseTextId = `response-text-${Date.now()}`;
            let audioQueue = [];
            let isPlaying = false;

            conversationElement.prepend(`<p id="${responseTextId}">インタビュイー: </p>`);

            $.ajax({
                url: '/llm_stream',
                type: 'POST',
                contentType: 'application/json',
                data: JSON.stringify({ message: usertext }),
                success: function(response) {
                    const eventSource = new EventSource('/llm_stream');

                    eventSource.onmessage = function(event) {
                        const data = JSON.parse(event.data);

                        if (data.text) {
                            // 文字データを受け取り表示する
                            const responseTextElement = document.getElementById(responseTextId);
                            responseTextElement.innerText += data.text;
                        }

                        if (data.audio) {
                            // 音声データを受け取りキューに追加する
                            const audioBlob = base64ToBlob(data.audio, 'audio/wav');
                            audioQueue.push(audioBlob);
                            playNextAudio();
                        }

                        if (data.completed) {
                            eventSource.close();
                            $('#status').text('停止中');
                            updateButtonStates();
                        }
                    };

                    eventSource.onerror = function() {
                        eventSource.close();
                        $('#status').text('停止中, Streaming生成失敗');
                    };
                },
                error: function() {
                    $('#status').text('停止中, Streaming開始失敗');
                }
            });

            function playNextAudio() {
                if (isPlaying || audioQueue.length === 0) {
                    return;
                }

                const audioBlob = audioQueue.shift();
                const audioUrl = URL.createObjectURL(audioBlob);
                audioElement.src = audioUrl;
                isPlaying = true;

                audioElement.onended = function() {
                    isPlaying = false;
                    playNextAudio();
                };

                audioElement.play();
            }
        }

        /*一気通貫のバックエンドの場合の処理*/
        /*
        function sendRecording_old(blob) {
            const formData = new FormData();
            formData.append('audio', blob, 'recording.wav');

            $.ajax({
                url: '/start',
                type: 'POST',
                data: formData,
                processData: false,
                contentType: false,
                success: function(response) {
                    handleInteractionResponse(response);
                }
            });
        }

        function handleInteractionResponse(response) {
            const audioBase64 = response.audio;
            const audioBlob = base64ToBlob(audioBase64, 'audio/wav');
            const audioUrl = URL.createObjectURL(audioBlob);
            const audioElement = document.getElementById('response-audio');
            audioElement.src = audioUrl;
            audioElement.style.display = 'block';
            audioElement.play();

            $('#conversation').prepend(`<p>User: ${response.user}</p>`);
            $('#conversation').prepend(`<p>Assistant: ${response.assistant}</p>`);
            $('#status').text('停止中');
            updateButtonStates();
        }
        */
        function base64ToBlob(base64, type) {
            const binary = atob(base64.replace(/\s/g, ''));
            const len = binary.length;
            const buffer = new ArrayBuffer(len);
            const view = new Uint8Array(buffer);
            for (let i = 0; i < len; i++) {
                view[i] = binary.charCodeAt(i);
            }
            return new Blob([view], { type: type });
        }

        function updateButtonStates() {
            if (isRecording) {
                $('#start-button').prop('disabled', true);
                $('#stop-button').prop('disabled', false);
            } else {
                $('#start-button').prop('disabled', false);
                $('#stop-button').prop('disabled', true);
            }
        }

        $(document).ready(function() {
            updateStatus();
        });

        function updateStatus() {
            $.get('/status', function(response) {
                $('#status').text(response.status);
                updateButtonStates();
            });
        }
    </script>
</body>
</html>
